{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4fe63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q youtube-comment-downloader yt-dlp pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80356e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TARGET_SIZE = 100_000  # target number of videos to collect\n",
    "BATCH_SIZE = 100  # number of videos to fetch per query\n",
    "MAX_DURATION = 60  # max duration in seconds (for shorts)\n",
    "\n",
    "OUTPUT_DIR = \"youtube_shorts_dataset\"\n",
    "ID_OUTPUT_PATH = f\"{OUTPUT_DIR}/video_ids.csv\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e463d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing IDs: 3747 -> skipping already collected videos\n",
      "Target: 100000 / Current: 3747 / Need to add: 96253\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Step 0. ê¸°ì¡´ ID ë¡œë“œ (ì¤‘ë³µ ë°©ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(ID_OUTPUT_PATH):\n",
    "    existing_df = pd.read_csv(ID_OUTPUT_PATH)\n",
    "    seen = set(existing_df[\"video_id\"].dropna().tolist())\n",
    "    print(\n",
    "        f\"Loaded existing IDs: {len(seen)} -> skipping already collected videos\"\n",
    "    )\n",
    "else:\n",
    "    seen = set()\n",
    "    print(\"No existing file found -> starting fresh\")\n",
    "\n",
    "print(\n",
    "    f\"Target: {TARGET_SIZE} / Current: {len(seen)} / Need to add: {max(0, TARGET_SIZE - len(seen))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b8a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of queries: 49\n",
      "100 results per query â†’ max candidates: 4,900\n",
      "Sample queries: ['funny #shorts', 'viral #shorts', 'trending #shorts', 'satisfying #shorts', 'meme #shorts']\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Step 1. Define search query list â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Query diversity directly improves dataset diversity\n",
    "\n",
    "GENERAL_QUERIES = [\n",
    "    # viral\n",
    "    \"funny\",\n",
    "    \"viral\",\n",
    "    \"trending\",\n",
    "    \"satisfying\",\n",
    "    # meme\n",
    "    \"meme\",\n",
    "    \"funny meme\",\n",
    "    \"relatable\",\n",
    "    # food\n",
    "    \"food\",\n",
    "    \"cooking\",\n",
    "    \"recipe\",\n",
    "    \"asmr food\",\n",
    "    # animals\n",
    "    \"animals\",\n",
    "    \"cute dog\",\n",
    "    \"dog\",\n",
    "    \"cute cat\",\n",
    "    \"cat\",\n",
    "    # sports\n",
    "    \"sports\",\n",
    "    \"basketball\",\n",
    "    \"soccer\",\n",
    "    \"gym\",\n",
    "    # games\n",
    "    \"gaming\",\n",
    "    \"minecraft\",\n",
    "    \"roblox\",\n",
    "    # beauty/fashion\n",
    "    \"makeup\",\n",
    "    \"fashion\",\n",
    "    \"outfit\",\n",
    "    # music\n",
    "    \"music\",\n",
    "    \"dance\",\n",
    "    \"singing\",\n",
    "    # education\n",
    "    \"did you know\",\n",
    "    \"facts\",\n",
    "    \"life hack\",\n",
    "    # etc\n",
    "    \"prank\",\n",
    "    \"challenge\",\n",
    "    \"travel\",\n",
    "    \"nature\",\n",
    "    \"science\",\n",
    "    \"art\",\n",
    "    \"diy\",\n",
    "    \"comedy\",\n",
    "]\n",
    "\n",
    "TRENDING_QUERIES = [\n",
    "    # --------- treding.google.com filtering youtube\n",
    "    # trending topics (2026)\n",
    "    \"half-life\",\n",
    "    \"ai\",\n",
    "    \"olympics\",\n",
    "    \"bad bunny\",\n",
    "    # trending topics (2025)\n",
    "    \"kpop demon hunters\",\n",
    "    \"soda pop\",\n",
    "    \"67\",\n",
    "    # ---------\n",
    "]\n",
    "\n",
    "MADE_UP_QUERIES = [\n",
    "    \"fyp\",\n",
    "    \"\",  # for general shorts without specific keywords\n",
    "]\n",
    "\n",
    "BASE_QUERIES = GENERAL_QUERIES + TRENDING_QUERIES + MADE_UP_QUERIES\n",
    "# BASE_QUERIES = MADE_UP_QUERIES\n",
    "\n",
    "QUERIES = []\n",
    "for q in BASE_QUERIES:\n",
    "    QUERIES.append(f\"{q} #shorts\")\n",
    "\n",
    "print(f\"Total number of queries: {len(QUERIES)}\")\n",
    "print(\n",
    "    f\"{BATCH_SIZE} results per query â†’ max candidates: {len(QUERIES) * BATCH_SIZE:,}\"\n",
    ")\n",
    "print(\"Sample queries:\", QUERIES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4e8f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3747/100000] Searching: 'funny #shorts'\n",
      "[3767/100000] Searching: 'viral #shorts'\n",
      "[3791/100000] Searching: 'trending #shorts'\n",
      "[3833/100000] Searching: 'satisfying #shorts'\n",
      "[3849/100000] Searching: 'meme #shorts'\n",
      "[3853/100000] Searching: 'funny meme #shorts'\n",
      "[3857/100000] Searching: 'relatable #shorts'\n",
      "[3887/100000] Searching: 'food #shorts'\n",
      "[3903/100000] Searching: 'cooking #shorts'\n",
      "[3907/100000] Searching: 'recipe #shorts'\n",
      "[3911/100000] Searching: 'asmr food #shorts'\n",
      "[3911/100000] Searching: 'animals #shorts'\n",
      "[3911/100000] Searching: 'cute dog #shorts'\n",
      "[3915/100000] Searching: 'dog #shorts'\n",
      "[4025/100000] Searching: 'cute cat #shorts'\n",
      "[4025/100000] Searching: 'cat #shorts'\n",
      "[4065/100000] Searching: 'sports #shorts'\n",
      "[4091/100000] Searching: 'basketball #shorts'\n",
      "[4107/100000] Searching: 'soccer #shorts'\n",
      "[4113/100000] Searching: 'gym #shorts'\n",
      "[4119/100000] Searching: 'gaming #shorts'\n",
      "[4137/100000] Searching: 'minecraft #shorts'\n",
      "[4147/100000] Searching: 'roblox #shorts'\n",
      "[4149/100000] Searching: 'makeup #shorts'\n",
      "[4151/100000] Searching: 'fashion #shorts'\n",
      "[4159/100000] Searching: 'outfit #shorts'\n",
      "[4171/100000] Searching: 'music #shorts'\n",
      "[4189/100000] Searching: 'dance #shorts'\n",
      "[4197/100000] Searching: 'singing #shorts'\n",
      "[4201/100000] Searching: 'did you know #shorts'\n",
      "[4205/100000] Searching: 'facts #shorts'\n",
      "[4213/100000] Searching: 'life hack #shorts'\n",
      "[4213/100000] Searching: 'prank #shorts'\n",
      "[4215/100000] Searching: 'challenge #shorts'\n",
      "[4221/100000] Searching: 'travel #shorts'\n",
      "[4231/100000] Searching: 'nature #shorts'\n",
      "[4237/100000] Searching: 'science #shorts'\n",
      "[4237/100000] Searching: 'art #shorts'\n",
      "[4255/100000] Searching: 'diy #shorts'\n",
      "[4265/100000] Searching: 'comedy #shorts'\n",
      "[4273/100000] Searching: 'half-life #shorts'\n",
      "[4275/100000] Searching: 'ai #shorts'\n",
      "[4277/100000] Searching: 'olympics #shorts'\n",
      "[4277/100000] Searching: 'bad bunny #shorts'\n",
      "[4277/100000] Searching: 'kpop demon hunters #shorts'\n",
      "[4281/100000] Searching: 'soda pop #shorts'\n",
      "[4281/100000] Searching: '67 #shorts'\n",
      "[4281/100000] Searching: 'fyp #shorts'\n",
      "[4287/100000] Searching: ' #shorts'\n",
      "\n",
      "Completed: 275 new videos collected\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Step 2. Collect IDs by iterating through queries â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import yt_dlp\n",
    "\n",
    "ydl_opts = {\n",
    "    \"quiet\": True,\n",
    "    \"extract_flat\": True,\n",
    "    \"skip_download\": True,\n",
    "}\n",
    "\n",
    "newly_collected = []\n",
    "need = TARGET_SIZE - len(seen)\n",
    "\n",
    "for query in QUERIES:\n",
    "    if len(newly_collected) >= need:\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"[{len(seen) + len(newly_collected)}/{TARGET_SIZE}] Searching: '{query}'\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            result = ydl.extract_info(\n",
    "                f\"ytsearch{BATCH_SIZE}:{query}\", download=False\n",
    "            )\n",
    "        entries = result.get(\"entries\", [])\n",
    "    except Exception as ex:\n",
    "        print(f\"  â†³ error: {ex}\")\n",
    "        continue\n",
    "\n",
    "    for e in entries:\n",
    "        if len(newly_collected) >= need:\n",
    "            break\n",
    "\n",
    "        vid = e.get(\"id\")\n",
    "        if not vid or vid in seen:\n",
    "            continue\n",
    "\n",
    "        duration = e.get(\"duration\")\n",
    "        if duration is not None and duration > MAX_DURATION:\n",
    "            continue\n",
    "\n",
    "        seen.add(vid)\n",
    "        newly_collected.append(\n",
    "            {\n",
    "                \"video_id\": vid,\n",
    "                \"title\": e.get(\"title\", \"\"),\n",
    "                \"duration\": duration,\n",
    "                \"view_count\": e.get(\"view_count\"),\n",
    "                \"url\": f\"https://www.youtube.com/shorts/{vid}\",\n",
    "                \"query\": query,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"\\nCompleted: {len(newly_collected)} new videos collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136b5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 275 new videos â†’ youtube_shorts_dataset/video_ids.csv\n",
      "Total accumulated: 4022 videos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>view_count</th>\n",
       "      <th>url</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>xgHaL-A81-E</td>\n",
       "      <td>GRANNY 1 KHELE ðŸ”¥ #shortsfeed #shortslive #chai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/shorts/xgHaL-A81-E</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>as6SkfSMrLU</td>\n",
       "      <td>Missing Animals Caught on Video ðŸ˜± #shorts</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12934.0</td>\n",
       "      <td>https://www.youtube.com/shorts/as6SkfSMrLU</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>MaSoCXtBW_g</td>\n",
       "      <td>1VS4 ON LIVE || WAIT FOR END END || #freefire ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/shorts/MaSoCXtBW_g</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>_E5Rpsh6JuY</td>\n",
       "      <td>GTA 5 Epic Water Ragdolls | Spider-Man Jumps /...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>62405.0</td>\n",
       "      <td>https://www.youtube.com/shorts/_E5Rpsh6JuY</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>QGGiRRbFoHQ</td>\n",
       "      <td>Gabriel no longer believes in God.#foryou #sho...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6496.0</td>\n",
       "      <td>https://www.youtube.com/shorts/QGGiRRbFoHQ</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "4017  xgHaL-A81-E  GRANNY 1 KHELE ðŸ”¥ #shortsfeed #shortslive #chai...   \n",
       "4018  as6SkfSMrLU          Missing Animals Caught on Video ðŸ˜± #shorts   \n",
       "4019  MaSoCXtBW_g  1VS4 ON LIVE || WAIT FOR END END || #freefire ...   \n",
       "4020  _E5Rpsh6JuY  GTA 5 Epic Water Ragdolls | Spider-Man Jumps /...   \n",
       "4021  QGGiRRbFoHQ  Gabriel no longer believes in God.#foryou #sho...   \n",
       "\n",
       "      duration  view_count                                         url  \\\n",
       "4017       NaN         NaN  https://www.youtube.com/shorts/xgHaL-A81-E   \n",
       "4018      22.0     12934.0  https://www.youtube.com/shorts/as6SkfSMrLU   \n",
       "4019       NaN         NaN  https://www.youtube.com/shorts/MaSoCXtBW_g   \n",
       "4020      16.0     62405.0  https://www.youtube.com/shorts/_E5Rpsh6JuY   \n",
       "4021      56.0      6496.0  https://www.youtube.com/shorts/QGGiRRbFoHQ   \n",
       "\n",
       "         query  \n",
       "4017   #shorts  \n",
       "4018   #shorts  \n",
       "4019   #shorts  \n",
       "4020   #shorts  \n",
       "4021   #shorts  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# â”€â”€ Step 3. Append new data to existing CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "new_df = pd.DataFrame(newly_collected)\n",
    "\n",
    "if os.path.exists(ID_OUTPUT_PATH) and len(newly_collected) > 0:\n",
    "    new_df.to_csv(ID_OUTPUT_PATH, mode=\"a\", header=False, index=False)\n",
    "    print(f\"Appended {len(new_df)} new videos â†’ {ID_OUTPUT_PATH}\")\n",
    "elif len(newly_collected) > 0:\n",
    "    new_df.to_csv(ID_OUTPUT_PATH, index=False)\n",
    "    print(f\"Saved {len(new_df)} new videos â†’ {ID_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"No new videos collected\")\n",
    "\n",
    "total = pd.read_csv(ID_OUTPUT_PATH)\n",
    "print(f\"Total accumulated: {len(total)} videos\")\n",
    "total.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
