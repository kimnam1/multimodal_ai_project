{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fe63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q youtube-comment-downloader yt-dlp pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80356e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ ÏÑ§Ï†ï ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "TARGET_SIZE = 100_000  # target number of videos to collect\n",
    "BATCH_SIZE = 500  # number of videos to fetch per query\n",
    "MAX_DURATION = 60  # max duration in seconds (for shorts)\n",
    "\n",
    "OUTPUT_DIR = \"youtube_shorts_dataset\"\n",
    "ID_OUTPUT_PATH = f\"{OUTPUT_DIR}/video_ids.csv\"\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e463d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing IDs: 4022 -> skipping already collected videos\n",
      "Target: 100000 / Current: 4022 / Need to add: 95978\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 0. Í∏∞Ï°¥ ID Î°úÎìú (Ï§ëÎ≥µ Î∞©ÏßÄ) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(ID_OUTPUT_PATH):\n",
    "    existing_df = pd.read_csv(ID_OUTPUT_PATH)\n",
    "    seen = set(existing_df[\"video_id\"].dropna().tolist())\n",
    "    print(\n",
    "        f\"Loaded existing IDs: {len(seen)} -> skipping already collected videos\"\n",
    "    )\n",
    "else:\n",
    "    seen = set()\n",
    "    print(\"No existing file found -> starting fresh\")\n",
    "\n",
    "print(\n",
    "    f\"Target: {TARGET_SIZE} / Current: {len(seen)} / Need to add: {max(0, TARGET_SIZE - len(seen))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b8a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of queries: 49\n",
      "100 results per query ‚Üí max candidates: 4,900\n",
      "Sample queries: ['funny #shorts', 'viral #shorts', 'trending #shorts', 'satisfying #shorts', 'meme #shorts']\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 1. Define search query list ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Query diversity directly improves dataset diversity\n",
    "\n",
    "GENERAL_QUERIES = [\n",
    "    # viral\n",
    "    \"funny\",\n",
    "    \"viral\",\n",
    "    \"trending\",\n",
    "    \"satisfying\",\n",
    "    # meme\n",
    "    \"meme\",\n",
    "    \"funny meme\",\n",
    "    \"relatable\",\n",
    "    # food\n",
    "    \"food\",\n",
    "    \"cooking\",\n",
    "    \"recipe\",\n",
    "    \"asmr food\",\n",
    "    # animals\n",
    "    \"animals\",\n",
    "    \"cute dog\",\n",
    "    \"dog\",\n",
    "    \"cute cat\",\n",
    "    \"cat\",\n",
    "    # sports\n",
    "    \"sports\",\n",
    "    \"basketball\",\n",
    "    \"soccer\",\n",
    "    \"gym\",\n",
    "    # games\n",
    "    \"gaming\",\n",
    "    \"minecraft\",\n",
    "    \"roblox\",\n",
    "    # beauty/fashion\n",
    "    \"makeup\",\n",
    "    \"fashion\",\n",
    "    \"outfit\",\n",
    "    # music\n",
    "    \"music\",\n",
    "    \"dance\",\n",
    "    \"singing\",\n",
    "    # education\n",
    "    \"did you know\",\n",
    "    \"facts\",\n",
    "    \"life hack\",\n",
    "    # etc\n",
    "    \"prank\",\n",
    "    \"challenge\",\n",
    "    \"travel\",\n",
    "    \"nature\",\n",
    "    \"science\",\n",
    "    \"art\",\n",
    "    \"diy\",\n",
    "    \"comedy\",\n",
    "]\n",
    "\n",
    "TRENDING_QUERIES = [\n",
    "    # --------- treding.google.com filtering youtube\n",
    "    # trending topics (2026)\n",
    "    \"half-life\",\n",
    "    \"ai\",\n",
    "    \"olympics\",\n",
    "    \"bad bunny\",\n",
    "    # trending topics (2025)\n",
    "    \"kpop demon hunters\",\n",
    "    \"soda pop\",\n",
    "    \"67\",\n",
    "    # ---------\n",
    "]\n",
    "\n",
    "MADE_UP_QUERIES = [\n",
    "    \"fyp\",\n",
    "    \"\",  # for general shorts without specific keywords\n",
    "]\n",
    "\n",
    "BASE_QUERIES = GENERAL_QUERIES + TRENDING_QUERIES + MADE_UP_QUERIES\n",
    "# BASE_QUERIES = MADE_UP_QUERIES\n",
    "\n",
    "QUERIES = []\n",
    "for q in BASE_QUERIES:\n",
    "    QUERIES.append(f\"{q} #shorts\")\n",
    "\n",
    "print(f\"Total number of queries: {len(QUERIES)}\")\n",
    "print(\n",
    "    f\"{BATCH_SIZE} results per query ‚Üí max candidates: {len(QUERIES) * BATCH_SIZE:,}\"\n",
    ")\n",
    "print(\"Sample queries:\", QUERIES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4e8f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4022/100000] Searching: 'funny #shorts'\n",
      "[4040/100000] Searching: 'viral #shorts'\n",
      "[4082/100000] Searching: 'trending #shorts'\n",
      "[4168/100000] Searching: 'satisfying #shorts'\n",
      "[4206/100000] Searching: 'meme #shorts'\n",
      "[4236/100000] Searching: 'funny meme #shorts'\n",
      "[4240/100000] Searching: 'relatable #shorts'\n",
      "[4334/100000] Searching: 'food #shorts'\n",
      "[4380/100000] Searching: 'cooking #shorts'\n",
      "[4406/100000] Searching: 'recipe #shorts'\n",
      "[4458/100000] Searching: 'asmr food #shorts'\n",
      "[4486/100000] Searching: 'animals #shorts'\n",
      "[4486/100000] Searching: 'cute dog #shorts'\n",
      "[4516/100000] Searching: 'dog #shorts'\n",
      "[4544/100000] Searching: 'cute cat #shorts'\n",
      "[4576/100000] Searching: 'cat #shorts'\n",
      "[4608/100000] Searching: 'sports #shorts'\n",
      "[4638/100000] Searching: 'basketball #shorts'\n",
      "[4658/100000] Searching: 'soccer #shorts'\n",
      "[4672/100000] Searching: 'gym #shorts'\n",
      "[4708/100000] Searching: 'gaming #shorts'\n",
      "[4758/100000] Searching: 'minecraft #shorts'\n",
      "[4810/100000] Searching: 'roblox #shorts'\n",
      "[4826/100000] Searching: 'makeup #shorts'\n",
      "[4860/100000] Searching: 'fashion #shorts'\n",
      "[4878/100000] Searching: 'outfit #shorts'\n",
      "[4902/100000] Searching: 'music #shorts'\n",
      "[4926/100000] Searching: 'dance #shorts'\n",
      "[5008/100000] Searching: 'singing #shorts'\n",
      "[5044/100000] Searching: 'did you know #shorts'\n",
      "[5058/100000] Searching: 'facts #shorts'\n",
      "[5094/100000] Searching: 'life hack #shorts'\n",
      "[5098/100000] Searching: 'prank #shorts'\n",
      "[5118/100000] Searching: 'challenge #shorts'\n",
      "[5156/100000] Searching: 'travel #shorts'\n",
      "[5204/100000] Searching: 'nature #shorts'\n",
      "[5228/100000] Searching: 'science #shorts'\n",
      "[5234/100000] Searching: 'art #shorts'\n",
      "[5316/100000] Searching: 'diy #shorts'\n",
      "[5350/100000] Searching: 'comedy #shorts'\n",
      "[5400/100000] Searching: 'half-life #shorts'\n",
      "[5406/100000] Searching: 'ai #shorts'\n",
      "[5434/100000] Searching: 'olympics #shorts'\n",
      "[5438/100000] Searching: 'bad bunny #shorts'\n",
      "[5472/100000] Searching: 'kpop demon hunters #shorts'\n",
      "[5490/100000] Searching: 'soda pop #shorts'\n",
      "[5508/100000] Searching: '67 #shorts'\n",
      "[5514/100000] Searching: 'fyp #shorts'\n",
      "[5586/100000] Searching: ' #shorts'\n",
      "\n",
      "Completed: 796 new videos collected\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 2. Collect IDs by iterating through queries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import yt_dlp\n",
    "\n",
    "ydl_opts = {\n",
    "    \"quiet\": True,\n",
    "    \"extract_flat\": True,\n",
    "    \"skip_download\": True,\n",
    "}\n",
    "\n",
    "newly_collected = []\n",
    "need = TARGET_SIZE - len(seen)\n",
    "\n",
    "for query in QUERIES:\n",
    "    if len(newly_collected) >= need:\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"[{len(seen) + len(newly_collected)}/{TARGET_SIZE}] Searching: '{query}'\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            result = ydl.extract_info(\n",
    "                f\"ytsearch{BATCH_SIZE}:{query}\", download=False\n",
    "            )\n",
    "        entries = result.get(\"entries\", [])\n",
    "    except Exception as ex:\n",
    "        print(f\"  ‚Ü≥ error: {ex}\")\n",
    "        continue\n",
    "\n",
    "    for e in entries:\n",
    "        if len(newly_collected) >= need:\n",
    "            break\n",
    "\n",
    "        vid = e.get(\"id\")\n",
    "        if not vid or vid in seen:\n",
    "            continue\n",
    "\n",
    "        duration = e.get(\"duration\")\n",
    "        if duration is not None and duration > MAX_DURATION:\n",
    "            continue\n",
    "\n",
    "        seen.add(vid)\n",
    "        newly_collected.append(\n",
    "            {\n",
    "                \"video_id\": vid,\n",
    "                \"title\": e.get(\"title\", \"\"),\n",
    "                \"duration\": duration,\n",
    "                \"view_count\": e.get(\"view_count\"),\n",
    "                \"url\": f\"https://www.youtube.com/shorts/{vid}\",\n",
    "                \"query\": query,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"\\nCompleted: {len(newly_collected)} new videos collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136b5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 796 new videos ‚Üí youtube_shorts_dataset/video_ids.csv\n",
      "Total accumulated: 4818 videos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>view_count</th>\n",
       "      <th>url</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>eFOf2i5Jeu8</td>\n",
       "      <td>WOW!!! So Satisfying! üòç Ice Ball with Doll! #s...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7691.0</td>\n",
       "      <td>https://www.youtube.com/shorts/eFOf2i5Jeu8</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>H2UC5EMxh5w</td>\n",
       "      <td>Redemption Mailday From Topps! What Did We Get...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>https://www.youtube.com/shorts/H2UC5EMxh5w</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>u6ls0ITaxYI</td>\n",
       "      <td>Realme GT 7T Video Test 4k #shorts</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.youtube.com/shorts/u6ls0ITaxYI</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>ftF2JZHvI9Q</td>\n",
       "      <td>#shorts –û–ë–ù–û–í–õ–ï–ù–ò–ï –≤ –¶–£–ù–ê–ú–ò –∏ –≤ Steal a Brainr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/shorts/ftF2JZHvI9Q</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>VYbYL1eXIgQ</td>\n",
       "      <td>Suzuki Gixxer SF üî•#suzuki #gixxer #bikelife #b...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>https://www.youtube.com/shorts/VYbYL1eXIgQ</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "4813  eFOf2i5Jeu8  WOW!!! So Satisfying! üòç Ice Ball with Doll! #s...   \n",
       "4814  H2UC5EMxh5w  Redemption Mailday From Topps! What Did We Get...   \n",
       "4815  u6ls0ITaxYI                 Realme GT 7T Video Test 4k #shorts   \n",
       "4816  ftF2JZHvI9Q  #shorts –û–ë–ù–û–í–õ–ï–ù–ò–ï –≤ –¶–£–ù–ê–ú–ò –∏ –≤ Steal a Brainr...   \n",
       "4817  VYbYL1eXIgQ  Suzuki Gixxer SF üî•#suzuki #gixxer #bikelife #b...   \n",
       "\n",
       "      duration  view_count                                         url  \\\n",
       "4813       8.0      7691.0  https://www.youtube.com/shorts/eFOf2i5Jeu8   \n",
       "4814      54.0       734.0  https://www.youtube.com/shorts/H2UC5EMxh5w   \n",
       "4815      42.0         0.0  https://www.youtube.com/shorts/u6ls0ITaxYI   \n",
       "4816       NaN         NaN  https://www.youtube.com/shorts/ftF2JZHvI9Q   \n",
       "4817      12.0       641.0  https://www.youtube.com/shorts/VYbYL1eXIgQ   \n",
       "\n",
       "         query  \n",
       "4813   #shorts  \n",
       "4814   #shorts  \n",
       "4815   #shorts  \n",
       "4816   #shorts  \n",
       "4817   #shorts  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 3. Append new data to existing CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "new_df = pd.DataFrame(newly_collected)\n",
    "\n",
    "if os.path.exists(ID_OUTPUT_PATH) and len(newly_collected) > 0:\n",
    "    new_df.to_csv(ID_OUTPUT_PATH, mode=\"a\", header=False, index=False)\n",
    "    print(f\"Appended {len(new_df)} new videos ‚Üí {ID_OUTPUT_PATH}\")\n",
    "elif len(newly_collected) > 0:\n",
    "    new_df.to_csv(ID_OUTPUT_PATH, index=False)\n",
    "    print(f\"Saved {len(new_df)} new videos ‚Üí {ID_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"No new videos collected\")\n",
    "\n",
    "total = pd.read_csv(ID_OUTPUT_PATH)\n",
    "print(f\"Total accumulated: {len(total)} videos\")\n",
    "total.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
