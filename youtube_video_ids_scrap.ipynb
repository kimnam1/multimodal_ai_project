{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fe63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q youtube-comment-downloader yt-dlp pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80356e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ ÏÑ§Ï†ï ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "TARGET_SIZE = 100_000  # target number of videos to collect\n",
    "BATCH_SIZE = 500  # number of videos to fetch per query\n",
    "MAX_DURATION = 60  # max duration in seconds (for shorts)\n",
    "\n",
    "OUTPUT_DIR = \"youtube_shorts_dataset\"\n",
    "ID_OUTPUT_PATH = f\"{OUTPUT_DIR}/video_ids.csv\"\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e463d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing IDs: 4818 -> skipping already collected videos\n",
      "Target: 100000 / Current: 4818 / Need to add: 95182\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 0. Í∏∞Ï°¥ ID Î°úÎìú (Ï§ëÎ≥µ Î∞©ÏßÄ) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(ID_OUTPUT_PATH):\n",
    "    existing_df = pd.read_csv(ID_OUTPUT_PATH)\n",
    "    seen = set(existing_df[\"video_id\"].dropna().tolist())\n",
    "    print(\n",
    "        f\"Loaded existing IDs: {len(seen)} -> skipping already collected videos\"\n",
    "    )\n",
    "else:\n",
    "    seen = set()\n",
    "    print(\"No existing file found -> starting fresh\")\n",
    "\n",
    "print(\n",
    "    f\"Target: {TARGET_SIZE} / Current: {len(seen)} / Need to add: {max(0, TARGET_SIZE - len(seen))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b8a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of queries: 49\n",
      "500 results per query ‚Üí max candidates: 24,500\n",
      "Sample queries: ['funny #shorts', 'viral #shorts', 'trending #shorts', 'satisfying #shorts', 'meme #shorts']\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 1. Define search query list ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Query diversity directly improves dataset diversity\n",
    "\n",
    "GENERAL_QUERIES = [\n",
    "    # viral\n",
    "    \"funny\",\n",
    "    \"viral\",\n",
    "    \"trending\",\n",
    "    \"satisfying\",\n",
    "    # meme\n",
    "    \"meme\",\n",
    "    \"funny meme\",\n",
    "    \"relatable\",\n",
    "    # food\n",
    "    \"food\",\n",
    "    \"cooking\",\n",
    "    \"recipe\",\n",
    "    \"asmr food\",\n",
    "    # animals\n",
    "    \"animals\",\n",
    "    \"cute dog\",\n",
    "    \"dog\",\n",
    "    \"cute cat\",\n",
    "    \"cat\",\n",
    "    # sports\n",
    "    \"sports\",\n",
    "    \"basketball\",\n",
    "    \"soccer\",\n",
    "    \"gym\",\n",
    "    # games\n",
    "    \"gaming\",\n",
    "    \"minecraft\",\n",
    "    \"roblox\",\n",
    "    # beauty/fashion\n",
    "    \"makeup\",\n",
    "    \"fashion\",\n",
    "    \"outfit\",\n",
    "    # music\n",
    "    \"music\",\n",
    "    \"dance\",\n",
    "    \"singing\",\n",
    "    # education\n",
    "    \"did you know\",\n",
    "    \"facts\",\n",
    "    \"life hack\",\n",
    "    # etc\n",
    "    \"prank\",\n",
    "    \"challenge\",\n",
    "    \"travel\",\n",
    "    \"nature\",\n",
    "    \"science\",\n",
    "    \"art\",\n",
    "    \"diy\",\n",
    "    \"comedy\",\n",
    "]\n",
    "\n",
    "TRENDING_QUERIES = [\n",
    "    # --------- treding.google.com filtering youtube\n",
    "    # trending topics (2026)\n",
    "    \"half-life\",\n",
    "    \"ai\",\n",
    "    \"olympics\",\n",
    "    \"bad bunny\",\n",
    "    # trending topics (2025)\n",
    "    \"kpop demon hunters\",\n",
    "    \"soda pop\",\n",
    "    \"67\",\n",
    "    # ---------\n",
    "]\n",
    "\n",
    "MADE_UP_QUERIES = [\n",
    "    \"fyp\",\n",
    "    \"\",  # for general shorts without specific keywords\n",
    "]\n",
    "\n",
    "BASE_QUERIES = GENERAL_QUERIES + TRENDING_QUERIES + MADE_UP_QUERIES\n",
    "# BASE_QUERIES = MADE_UP_QUERIES\n",
    "\n",
    "QUERIES = []\n",
    "for q in BASE_QUERIES:\n",
    "    QUERIES.append(f\"{q} #shorts\")\n",
    "\n",
    "print(f\"Total number of queries: {len(QUERIES)}\")\n",
    "print(\n",
    "    f\"{BATCH_SIZE} results per query ‚Üí max candidates: {len(QUERIES) * BATCH_SIZE:,}\"\n",
    ")\n",
    "print(\"Sample queries:\", QUERIES[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4e8f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4818/100000] Searching: 'funny #shorts'\n",
      "[4946/100000] Searching: 'viral #shorts'\n",
      "[5168/100000] Searching: 'trending #shorts'\n",
      "[5336/100000] Searching: 'satisfying #shorts'\n",
      "[5446/100000] Searching: 'meme #shorts'\n",
      "[5702/100000] Searching: 'funny meme #shorts'\n",
      "[5822/100000] Searching: 'relatable #shorts'\n",
      "[6244/100000] Searching: 'food #shorts'\n",
      "[6440/100000] Searching: 'cooking #shorts'\n",
      "[6512/100000] Searching: 'recipe #shorts'\n",
      "[6576/100000] Searching: 'asmr food #shorts'\n",
      "[6678/100000] Searching: 'animals #shorts'\n",
      "[6688/100000] Searching: 'cute dog #shorts'\n",
      "[6844/100000] Searching: 'dog #shorts'\n",
      "[7080/100000] Searching: 'cute cat #shorts'\n",
      "[7210/100000] Searching: 'cat #shorts'\n",
      "[7474/100000] Searching: 'sports #shorts'\n",
      "[7644/100000] Searching: 'basketball #shorts'\n",
      "[8046/100000] Searching: 'soccer #shorts'\n",
      "[8216/100000] Searching: 'gym #shorts'\n",
      "[8512/100000] Searching: 'gaming #shorts'\n",
      "[8636/100000] Searching: 'minecraft #shorts'\n",
      "[8744/100000] Searching: 'roblox #shorts'\n",
      "[8830/100000] Searching: 'makeup #shorts'\n",
      "[8892/100000] Searching: 'fashion #shorts'\n",
      "[8990/100000] Searching: 'outfit #shorts'\n",
      "[9188/100000] Searching: 'music #shorts'\n",
      "[9362/100000] Searching: 'dance #shorts'\n",
      "[9406/100000] Searching: 'singing #shorts'\n",
      "[9450/100000] Searching: 'did you know #shorts'\n",
      "[9584/100000] Searching: 'facts #shorts'\n",
      "[9870/100000] Searching: 'life hack #shorts'\n",
      "[10054/100000] Searching: 'prank #shorts'\n",
      "[10190/100000] Searching: 'challenge #shorts'\n",
      "[10616/100000] Searching: 'travel #shorts'\n",
      "[10794/100000] Searching: 'nature #shorts'\n",
      "[11128/100000] Searching: 'science #shorts'\n",
      "[11416/100000] Searching: 'art #shorts'\n",
      "[11662/100000] Searching: 'diy #shorts'\n",
      "[11816/100000] Searching: 'comedy #shorts'\n",
      "[11920/100000] Searching: 'half-life #shorts'\n",
      "[11940/100000] Searching: 'ai #shorts'\n",
      "[12010/100000] Searching: 'olympics #shorts'\n",
      "[12044/100000] Searching: 'bad bunny #shorts'\n",
      "[12130/100000] Searching: 'kpop demon hunters #shorts'\n",
      "[12188/100000] Searching: 'soda pop #shorts'\n",
      "[12230/100000] Searching: '67 #shorts'\n",
      "[12262/100000] Searching: 'fyp #shorts'\n",
      "[12370/100000] Searching: ' #shorts'\n",
      "\n",
      "Completed: 3790 new videos collected\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 2. Collect IDs by iterating through queries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import yt_dlp\n",
    "\n",
    "ydl_opts = {\n",
    "    \"quiet\": True,\n",
    "    \"extract_flat\": True,\n",
    "    \"skip_download\": True,\n",
    "}\n",
    "\n",
    "newly_collected = []\n",
    "need = TARGET_SIZE - len(seen)\n",
    "\n",
    "for query in QUERIES:\n",
    "    if len(newly_collected) >= need:\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"[{len(seen) + len(newly_collected)}/{TARGET_SIZE}] Searching: '{query}'\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            result = ydl.extract_info(\n",
    "                f\"ytsearch{BATCH_SIZE}:{query}\", download=False\n",
    "            )\n",
    "        entries = result.get(\"entries\", [])\n",
    "    except Exception as ex:\n",
    "        print(f\"  ‚Ü≥ error: {ex}\")\n",
    "        continue\n",
    "\n",
    "    for e in entries:\n",
    "        if len(newly_collected) >= need:\n",
    "            break\n",
    "\n",
    "        vid = e.get(\"id\")\n",
    "        if not vid or vid in seen:\n",
    "            continue\n",
    "\n",
    "        duration = e.get(\"duration\")\n",
    "        if duration is not None and duration > MAX_DURATION:\n",
    "            continue\n",
    "\n",
    "        seen.add(vid)\n",
    "        newly_collected.append(\n",
    "            {\n",
    "                \"video_id\": vid,\n",
    "                \"title\": e.get(\"title\", \"\"),\n",
    "                \"duration\": duration,\n",
    "                \"view_count\": e.get(\"view_count\"),\n",
    "                \"url\": f\"https://www.youtube.com/shorts/{vid}\",\n",
    "                \"query\": query,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"\\nCompleted: {len(newly_collected)} new videos collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136b5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 3790 new videos ‚Üí youtube_shorts_dataset/video_ids.csv\n",
      "Total accumulated: 8608 videos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>view_count</th>\n",
       "      <th>url</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8603</th>\n",
       "      <td>jHYdNvOBp3I</td>\n",
       "      <td>FINDS a lost PHONE and ends up ENGAGED! ‚ù§Ô∏èüì± #s...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.youtube.com/shorts/jHYdNvOBp3I</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8604</th>\n",
       "      <td>1vXbsttBl68</td>\n",
       "      <td>FOR THE LOVE OF MONEY&nbsp;&nbsp;|&nbsp;&nbsp;LATEST MOVIE | MR AL...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>693201.0</td>\n",
       "      <td>https://www.youtube.com/shorts/1vXbsttBl68</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8605</th>\n",
       "      <td>qb17TJ7k8Ck</td>\n",
       "      <td>guess the song üíñüòò #shorts #dance #youtubeshort...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>https://www.youtube.com/shorts/qb17TJ7k8Ck</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8606</th>\n",
       "      <td>tqxu4Ey4hNM</td>\n",
       "      <td>The gift Tal gave his nephew#foryou #series #s...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16739.0</td>\n",
       "      <td>https://www.youtube.com/shorts/tqxu4Ey4hNM</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8607</th>\n",
       "      <td>5piXXXtM2wo</td>\n",
       "      <td>whowillbemylifepartnerta #shortsviral #shortvi...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>https://www.youtube.com/shorts/5piXXXtM2wo</td>\n",
       "      <td>#shorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "8603  jHYdNvOBp3I  FINDS a lost PHONE and ends up ENGAGED! ‚ù§Ô∏èüì± #s...   \n",
       "8604  1vXbsttBl68  FOR THE LOVE OF MONEY  |  LATEST MOVIE | MR AL...   \n",
       "8605  qb17TJ7k8Ck  guess the song üíñüòò #shorts #dance #youtubeshort...   \n",
       "8606  tqxu4Ey4hNM  The gift Tal gave his nephew#foryou #series #s...   \n",
       "8607  5piXXXtM2wo  whowillbemylifepartnerta #shortsviral #shortvi...   \n",
       "\n",
       "      duration  view_count                                         url  \\\n",
       "8603      38.0         0.0  https://www.youtube.com/shorts/jHYdNvOBp3I   \n",
       "8604      26.0    693201.0  https://www.youtube.com/shorts/1vXbsttBl68   \n",
       "8605      23.0      1263.0  https://www.youtube.com/shorts/qb17TJ7k8Ck   \n",
       "8606      57.0     16739.0  https://www.youtube.com/shorts/tqxu4Ey4hNM   \n",
       "8607      45.0       943.0  https://www.youtube.com/shorts/5piXXXtM2wo   \n",
       "\n",
       "         query  \n",
       "8603   #shorts  \n",
       "8604   #shorts  \n",
       "8605   #shorts  \n",
       "8606   #shorts  \n",
       "8607   #shorts  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Step 3. Append new data to existing CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "new_df = pd.DataFrame(newly_collected)\n",
    "\n",
    "if os.path.exists(ID_OUTPUT_PATH) and len(newly_collected) > 0:\n",
    "    new_df.to_csv(ID_OUTPUT_PATH, mode=\"a\", header=False, index=False)\n",
    "    print(f\"Appended {len(new_df)} new videos ‚Üí {ID_OUTPUT_PATH}\")\n",
    "elif len(newly_collected) > 0:\n",
    "    new_df.to_csv(ID_OUTPUT_PATH, index=False)\n",
    "    print(f\"Saved {len(new_df)} new videos ‚Üí {ID_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"No new videos collected\")\n",
    "\n",
    "total = pd.read_csv(ID_OUTPUT_PATH)\n",
    "print(f\"Total accumulated: {len(total)} videos\")\n",
    "total.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
